{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep():\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "def pretty(x):\n",
    "    print('\\n'.join(['\\t'.join([str(cell) for cell in row]) for row in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t0\t1\t1\t1\t0\n",
      "4\t1\t4\t1\t4\t0\n",
      "0\t0\t2\t1\t2\t3\n",
      "4\t4\t4\t2\t1\t2\n",
      "4\t3\t1\t2\t2\t2\n",
      "1\t4\t1\t2\t1\t1\n"
     ]
    }
   ],
   "source": [
    "A = np.random.randint(0, 5, size=(6, 6))\n",
    "pretty(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel:\n",
      "1\t1\t1\n",
      "1\t1\t1\n",
      "1\t1\t1\n"
     ]
    }
   ],
   "source": [
    "kernel = np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]])\n",
    "print(\"Kernel:\")\n",
    "pretty(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(A, kernel):\n",
    "    A_row, A_col = A.shape   # A_row is height, A_col is width\n",
    "    kernel_row, kernel_col = kernel.shape\n",
    "    result = np.zeros((A_row - kernel_row + 1, A_col - kernel_col + 1))\n",
    "\n",
    "    for i in range(result.shape[0]):\n",
    "        for j in range(result.shape[1]):\n",
    "            result[i][j] = np.sum(A[i : i + kernel_row, j : j + kernel_col] * kernel)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(matrix, padding_size):\n",
    "    original_rows, original_cols = matrix.shape\n",
    "\n",
    "    # Create a new matrix filled with zeros, large enough to include the padding\n",
    "    padded_matrix = np.zeros((original_rows + 2 * padding_size, original_cols + 2 * padding_size))\n",
    "    \n",
    "    # Place the original matrix into the center of the padded matrix\n",
    "    padded_matrix[padding_size:-padding_size, padding_size:-padding_size] = matrix\n",
    "    \n",
    "    # Return the padded matrix\n",
    "    return padded_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded A:\n",
      "0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\n",
      "0.0\t1.0\t0.0\t1.0\t1.0\t1.0\t0.0\t0.0\n",
      "0.0\t4.0\t1.0\t4.0\t1.0\t4.0\t0.0\t0.0\n",
      "0.0\t0.0\t0.0\t2.0\t1.0\t2.0\t3.0\t0.0\n",
      "0.0\t4.0\t4.0\t4.0\t2.0\t1.0\t2.0\t0.0\n",
      "0.0\t4.0\t3.0\t1.0\t2.0\t2.0\t2.0\t0.0\n",
      "0.0\t1.0\t4.0\t1.0\t2.0\t1.0\t1.0\t0.0\n",
      "0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "[[ 6. 11.  8. 12.  7.  5.]\n",
      " [ 6. 13. 11. 17. 13. 10.]\n",
      " [13. 23. 19. 21. 16. 12.]\n",
      " [15. 22. 19. 17. 17. 12.]\n",
      " [20. 26. 23. 16. 15.  9.]\n",
      " [12. 14. 13.  9. 10.  6.]]\n"
     ]
    }
   ],
   "source": [
    "padded_A = pad(A, 1)\n",
    "print(\"Padded A:\")\n",
    "pretty(padded_A)\n",
    "sep()\n",
    "print(conv2d(padded_A, kernel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionLayer:\n",
    "    def __init__(self, kernel_size, num_filters):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_filters = num_filters\n",
    "        self.filters = np.random.randn(num_filters, kernel_size, kernel_size) / (kernel_size * kernel_size)\n",
    "\n",
    "    def generate_patches(self, A):\n",
    "        A_row, A_col = A.shape\n",
    "        for i in range(A_row - self.kernel_size + 1):\n",
    "            for j in range(A_col - self.kernel_size + 1):\n",
    "                patch = A[i : i + self.kernel_size, j : j + self.kernel_size]\n",
    "                yield patch, i, j\n",
    "    \n",
    "    def forward(self, A):\n",
    "        self.last_input = A\n",
    "        A_row, A_col = A.shape\n",
    "        output = np.zeros((A_row - self.kernel_size + 1, A_col - self.kernel_size + 1, self.num_filters))\n",
    "\n",
    "        for patch, i, j in self.generate_patches(A):\n",
    "            output[i, j] = np.sum(patch * self.filters, axis=(1, 2))\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def backprop(self, d_loss_d_output, learning_rate):\n",
    "        d_loss_d_filters = np.zeros(self.filters.shape)\n",
    "\n",
    "        # Iterate over patches in the last input \n",
    "        for patch, row, col in self.generate_patches(self.last_input):\n",
    "            # Update the gradient of the filters\n",
    "            for filter_index in range(self.num_filters):\n",
    "                d_loss_d_filters[filter_index] += d_loss_d_output[row, col, filter_index] * patch\n",
    "\n",
    "        # Update filters using the calculated gradient and learning rate\n",
    "        self.filters -= learning_rate * d_loss_d_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 3)\n",
      "[[[-0.01956709 -0.11426189  0.168255  ]\n",
      "  [-0.11077808  0.11077019  0.16379546]\n",
      "  [ 0.18256764 -0.11440878 -0.06811516]]\n",
      "\n",
      " [[ 0.10609209  0.02028943  0.0347009 ]\n",
      "  [ 0.15049159 -0.09504778 -0.11747802]\n",
      "  [ 0.18046569  0.11106658 -0.02686553]]]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "(array([[0., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 4., 1.]]), 0, 0)\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "(6, 6, 2)\n",
      "[[-0.41498009  0.39641849 -0.06861699  0.50718868 -0.27507537  0.61949247]\n",
      " [ 0.49261431  0.33529728  0.25315851  0.47176188 -0.05212173 -0.44077047]\n",
      " [-1.01888835  0.80825545  0.21338128  1.13063252  0.24003017 -0.01376387]\n",
      " [ 0.43628198  1.3105893   0.56435436 -0.05714281  0.47356645 -0.13483984]\n",
      " [ 0.76357011 -0.15248488  0.38685238  0.18545099  0.69330039 -0.1799478 ]\n",
      " [ 0.81366944  0.24329909  0.15879562  0.36297687  0.12186152 -0.26766586]]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn_layer = ConvolutionLayer(3, 2)\n",
    "print(cnn_layer.filters.shape)\n",
    "print(cnn_layer.filters)\n",
    "sep()\n",
    "\n",
    "patches = cnn_layer.generate_patches(padded_A)\n",
    "print(next(patches))\n",
    "sep()\n",
    "\n",
    "output = cnn_layer.forward(padded_A)\n",
    "print(output.shape)\n",
    "print(output[:, :, 0])\n",
    "sep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2d:\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "    \n",
    "    def generate_patches(self, A):\n",
    "        A_row, A_col, num_filters = A.shape\n",
    "        for i in range(0, A_row, self.pool_size):\n",
    "            for j in range(0, A_col, self.pool_size):\n",
    "                patch = A[i : i + self.pool_size, j : j + self.pool_size]\n",
    "                yield patch, i, j\n",
    "    \n",
    "    def forward(self, A):\n",
    "        self.last_input = A\n",
    "        A_row, A_col, num_filters = A.shape\n",
    "        output = np.zeros((A_row // self.pool_size, A_col // self.pool_size, num_filters))\n",
    "\n",
    "        for patch, i, j in self.generate_patches(A):\n",
    "            output[i//self.pool_size, j//self.pool_size] = np.amax(patch, axis=(0, 1))\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def backprop(self, d_loss_d_output):\n",
    "        d_loss_d_input = np.zeros(self.last_input.shape)\n",
    "\n",
    "        # Iterate over the regions as in forward pass\n",
    "        for patch, row, col in self.generate_patches(self.last_input):\n",
    "            patch_height, patch_width, num_channels = patch.shape\n",
    "            max_values = np.amax(patch, axis=(0, 1))\n",
    "\n",
    "            for i in range(patch_height):\n",
    "                for j in range(patch_width):\n",
    "                    for channel in range(num_channels):\n",
    "                        # Find the pizel that was the max value in this patch, and pass the gradient back to it\n",
    "                        if patch[i, j, channel] == max_values[channel]:\n",
    "                            d_loss_d_input[row + i, col + j, channel] = d_loss_d_output[row // self.pool_size, col // self.pool_size, channel]\n",
    "        \n",
    "        return d_loss_d_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 2)\n",
      "[[0.49261431 0.50718868 0.61949247]\n",
      " [1.3105893  1.13063252 0.47356645]\n",
      " [0.81366944 0.38685238 0.69330039]]\n"
     ]
    }
   ],
   "source": [
    "max_pool = MaxPool2d(2)\n",
    "output = max_pool.forward(output)\n",
    "print(output.shape)\n",
    "print(output[:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer:\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        self.weights = np.random.randn(num_inputs, num_outputs) / num_inputs\n",
    "        self.bias = np.zeros(num_outputs)\n",
    "    \n",
    "    def softmax(self, A):\n",
    "        expA = np.exp(A)\n",
    "        return expA / expA.sum(axis=0)\n",
    "\n",
    "    def forward(self, A):\n",
    "        self.shape_before_flattening = A.shape\n",
    "        A = A.flatten()\n",
    "        self.input_to_last_layer = A\n",
    "        input_size, output_size = self.weights.shape\n",
    "        self.logits = np.dot(A, self.weights) + self.bias\n",
    "        return self.softmax(self.logits)\n",
    "\n",
    "    def backprop(self, d_L_d_out, learn_rate):\n",
    "        for i, gradient in enumerate(d_L_d_out):\n",
    "            if gradient == 0:\n",
    "                continue\n",
    "\n",
    "            # e^t for every element of the output\n",
    "            a_exp = np.exp(self.logits)\n",
    "\n",
    "            # Sum of all e^t\n",
    "            S = np.sum(a_exp)\n",
    "\n",
    "            # Gradients of out[i] against totals (logits)\n",
    "            d_Z_d_a = -a_exp[i] * a_exp / (S ** 2)\n",
    "            d_Z_d_a[i] = a_exp[i] * (S - a_exp[i]) / (S ** 2)\n",
    "\n",
    "            # Gradients of totals (logits) against weights, biases, and inputs\n",
    "            d_a_d_w = self.input_to_last_layer  # Gradient of totals w.r.t weights\n",
    "            d_a_d_b = 1  # Gradient of totals w.r.t biases\n",
    "            d_a_d_inputs = self.weights  # Gradient of totals w.r.t inputs\n",
    "\n",
    "            # Gradient of the loss w.r.t totals (logits)\n",
    "            d_L_d_t = gradient * d_Z_d_a\n",
    "\n",
    "            # Gradient of the loss w.r.t weights, biases, and inputs\n",
    "            d_L_d_w = d_a_d_w[np.newaxis].T @ d_L_d_t[np.newaxis]\n",
    "            d_L_d_b = d_L_d_t * d_a_d_b\n",
    "            d_L_d_inputs = d_a_d_inputs @ d_L_d_t\n",
    "\n",
    "            # Update weights and biases using gradient descent\n",
    "            self.weights -= learn_rate * d_L_d_w\n",
    "            self.bias -= learn_rate * d_L_d_b\n",
    "\n",
    "            # Return the gradient of the loss w.r.t inputs\n",
    "            return d_L_d_inputs.reshape(self.shape_before_flattening)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12956719 0.22196892 0.24828219 0.20617273 0.19400897]\n"
     ]
    }
   ],
   "source": [
    "linear_layer = LinearLayer(18, 5)\n",
    "output = linear_layer.forward(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = pd.read_csv('mnist_train.csv')\n",
    "mnist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28, 28)\n",
      "(1000, 10)\n",
      "(500, 28, 28)\n",
      "(500,)\n",
      "[[  1 154 253  90   0   0   0   0   0   0]\n",
      " [  0 139 253 190   2   0   0   0   0   0]\n",
      " [  0  11 190 253  70   0   0   0   0   0]\n",
      " [  0   0  35 241 225 160 108   1   0   0]\n",
      " [  0   0   0  81 240 253 253 119  25   0]\n",
      " [  0   0   0   0  45 186 253 253 150  27]\n",
      " [  0   0   0   0   0  16  93 252 253 187]\n",
      " [  0   0   0   0   0   0   0 249 253 249]\n",
      " [  0   0   0   0  46 130 183 253 253 207]\n",
      " [  0   0  39 148 229 253 253 253 250 182]]\n"
     ]
    }
   ],
   "source": [
    "data = mnist.values\n",
    "split_index = int(0.8 * data.shape[0])\n",
    "data_train = data[:split_index]\n",
    "data_test = data[split_index:]\n",
    "\n",
    "# get random sample of 1000\n",
    "X = data[:1000, 1:].reshape(-1, 28, 28)\n",
    "y = data[:1000, 0]\n",
    "\n",
    "X_test = data[1500:2000, 1:].reshape(-1, 28, 28)\n",
    "y_test = data[1500:2000, 0]\n",
    "\n",
    "y_one_hot = np.zeros((y.shape[0], 10))\n",
    "y_one_hot[np.arange(y.shape[0]), y] = 1\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "print(y_one_hot.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(X[0, 10:20, 10:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_img(img):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "show_img(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, num_classes):\n",
    "        self.conv = ConvolutionLayer(3, 8)\n",
    "        self.pool = MaxPool2d(2)\n",
    "        # self.linear = LinearLayer(13 * 13 * 8, num_classes)\n",
    "        self.linear = LinearLayer(14 * 14 * 8, num_classes)\n",
    "        \n",
    "    \n",
    "    def forward(self, A):\n",
    "        output = self.conv.forward(A)\n",
    "        # print(\"After Convolution Layer:\")\n",
    "        # print(output.shape)\n",
    "        # sep()\n",
    "\n",
    "        output = self.pool.forward(output)\n",
    "        # print(\"After Max Pooling Layer:\")\n",
    "        # print(output.shape)\n",
    "        # sep()\n",
    "        \n",
    "        output = self.linear.forward(output)\n",
    "        # print(\"After Linear Layer:\")\n",
    "        # print(output.shape)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def backprop(self, y, y_hat, learn_rate):\n",
    "        grad = np.zeros(y.shape)\n",
    "        grad[np.argmax(y)] = -1 / y_hat[np.argmax(y)]\n",
    "\n",
    "        grad = self.linear.backprop(grad, learn_rate)\n",
    "        grad = self.pool.backprop(grad)\n",
    "        grad = self.conv.backprop(grad, learn_rate)\n",
    "\n",
    "        return grad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How is it 13x13x8?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input was an image of size 28x28\n",
    "Now, we have a kernel size of 3 x 3, so we will end up with a 28 - 3 + 1 = 26 x 26 image.\n",
    "Since we have 8 filters, we will end up with 26 x 26 x 8 image after the first convolutional layer.\n",
    "\n",
    "Now, we have a max pooling layer with a pool size of 2 x 2, so each block of 2 x 2 pixels will be reduced to 1 pixel. So, we will end up with a 13 x 13 x 8 image after the first max pooling layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_index = np.random.randint(0, X.shape[0])\n",
    "inp = pad(X[random_index], 1)\n",
    "inp = normalize(inp)\n",
    "\n",
    "output = cnn.forward(inp)\n",
    "print(output.shape)\n",
    "print(np.argmax(output))\n",
    "show_img(X[random_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y, y_hat):\n",
    "    return -np.sum(y * np.log(y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_accuracy():\n",
    "    correct = 0\n",
    "    for i in range(X_test.shape[0]):\n",
    "        inp = pad(X_test[i], 1)\n",
    "        inp = normalize(inp)\n",
    "        output = cnn.forward(inp)\n",
    "        if np.argmax(output) == y_test[i]:\n",
    "            correct += 1\n",
    "    return correct / X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.052"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(im, label, lr=.005):\n",
    "    # Forward\n",
    "    out = cnn.forward(im)\n",
    "    loss = cross_entropy_loss(label, out)\n",
    "    cnn.backprop(label, out, lr)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.10866504561883059, Accuracy: 0.417\n",
      "Epoch 2, Loss: 0.0834994601655843, Accuracy: 0.441\n",
      "Epoch 3, Loss: 0.053430469483054376, Accuracy: 0.433\n",
      "Epoch 4, Loss: 0.03690342002231515, Accuracy: 0.44\n",
      "Epoch 5, Loss: 0.02391962134572053, Accuracy: 0.44\n",
      "Epoch 6, Loss: 0.01708781693263299, Accuracy: 0.444\n",
      "Epoch 7, Loss: 0.013039423869068038, Accuracy: 0.445\n",
      "Epoch 8, Loss: 0.010578803588159663, Accuracy: 0.445\n",
      "Epoch 9, Loss: 0.00886390083673022, Accuracy: 0.445\n",
      "Epoch 10, Loss: 0.007600068493470269, Accuracy: 0.445\n",
      "Epoch 11, Loss: 0.006623727636900472, Accuracy: 0.446\n",
      "Epoch 12, Loss: 0.005847490957518882, Accuracy: 0.445\n",
      "Epoch 13, Loss: 0.005217739001754394, Accuracy: 0.445\n",
      "Epoch 14, Loss: 0.004699117519604556, Accuracy: 0.445\n",
      "Epoch 15, Loss: 0.0042668378742401316, Accuracy: 0.445\n",
      "Epoch 16, Loss: 0.003902076088800789, Accuracy: 0.445\n",
      "Epoch 17, Loss: 0.0035909536020176094, Accuracy: 0.444\n",
      "Epoch 18, Loss: 0.0033231403965474867, Accuracy: 0.444\n",
      "Epoch 19, Loss: 0.0030907023011545543, Accuracy: 0.444\n",
      "Epoch 20, Loss: 0.0028873382936468847, Accuracy: 0.444\n",
      "Epoch 21, Loss: 0.002708001151723708, Accuracy: 0.445\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [460], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m     inp \u001b[38;5;241m=\u001b[39m pad(X[i], \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m     inp \u001b[38;5;241m=\u001b[39m normalize(inp)\n\u001b[0;32m----> 6\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_one_hot\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_loss \u001b[38;5;241m/\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtesting_accuracy()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn [457], line 5\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(im, label, lr)\u001b[0m\n\u001b[1;32m      3\u001b[0m out \u001b[38;5;241m=\u001b[39m cnn\u001b[38;5;241m.\u001b[39mforward(im)\n\u001b[1;32m      4\u001b[0m loss \u001b[38;5;241m=\u001b[39m cross_entropy_loss(label, out)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackprop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "Cell \u001b[0;32mIn [447], line 32\u001b[0m, in \u001b[0;36mCNN.backprop\u001b[0;34m(self, y, y_hat, learn_rate)\u001b[0m\n\u001b[1;32m     30\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear\u001b[38;5;241m.\u001b[39mbackprop(grad, learn_rate)\n\u001b[1;32m     31\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mbackprop(grad)\n\u001b[0;32m---> 32\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackprop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearn_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad\n",
      "Cell \u001b[0;32mIn [433], line 31\u001b[0m, in \u001b[0;36mConvolutionLayer.backprop\u001b[0;34m(self, d_loss_d_output, learning_rate)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m patch, row, col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_patches(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_input):\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# Update the gradient of the filters\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filter_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_filters):\n\u001b[0;32m---> 31\u001b[0m         d_loss_d_filters[filter_index] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m d_loss_d_output[row, col, filter_index] \u001b[38;5;241m*\u001b[39m patch\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Update filters using the calculated gradient and learning rate\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilters \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m d_loss_d_filters\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    epoch_loss = 0\n",
    "    for i in range(X.shape[0]):\n",
    "        inp = pad(X[i], 1)\n",
    "        inp = normalize(inp)\n",
    "        loss = train(inp, y_one_hot[i])\n",
    "        epoch_loss += loss\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}, Loss: {epoch_loss / X.shape[0]}, Accuracy: {testing_accuracy()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
